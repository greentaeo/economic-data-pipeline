import requests
import time
import logging
import pandas as pd
import sys
from datetime import datetime, timedelta
from pathlib import Path

# --- [ì„¤ì • íŒŒì¼ ì—°ë™] ---
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œë¥¼ ì°¾ì•„ ì‹œìŠ¤í…œ ê²½ë¡œì— ì¶”ê°€ (config ëª¨ë“ˆ importìš©)
FILE = Path(__file__).resolve()
ROOT = FILE.parents[2]  # scripts/collection/ -> scripts/ -> root/
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

from config.settings import API_KEYS, DIRS, LOG_DIR

# --- [ë¡œê¹… ì„¤ì •] ---
# ë¡œê·¸ íŒŒì¼ë„ ì´ì œ ì²´ê³„ì ìœ¼ë¡œ logs í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.
log_file = LOG_DIR / 'etf_smart_collector.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file),
        logging.StreamHandler()
    ]
)


class ETFSmartCollector:
    def __init__(self, years_back=5):
        # settings.pyì—ì„œ API í‚¤ ê°€ì ¸ì˜¤ê¸°
        self.api_key = API_KEYS['TIINGO']
        if not self.api_key:
            raise ValueError("TIINGO_API_KEY is missing in .env or settings!")

        self.base_url = "https://api.tiingo.com"
        self.years_back = years_back

        # settings.pyì—ì„œ ì •ì˜í•œ ì™¸ì¥í•˜ë“œ ê²½ë¡œ ì‚¬ìš©
        self.etf_path = DIRS['etf']

        # ETF ë¦¬ìŠ¤íŠ¸ (ê¸°ì¡´ ìœ ì§€)
        self.etfs = {
            'SPY': 'S&P 500 ETF', 'QQQ': 'NASDAQ-100 ETF', 'DIA': 'Dow Jones ETF',
            'VTI': 'Total Stock Market ETF', 'IWM': 'Russell 2000 ETF', 'XLF': 'Financial Sector ETF',
            'XLK': 'Technology Sector ETF', 'XLE': 'Energy Sector ETF', 'XLV': 'Healthcare Sector ETF',
            'XLRE': 'Real Estate Sector ETF', 'EFA': 'Developed Markets ETF', 'EEM': 'Emerging Markets ETF',
            'VEA': 'Developed Markets Ex-US ETF', 'TLT': '20+ Year Treasury ETF', 'IEF': '7-10 Year Treasury ETF',
            'LQD': 'Investment Grade Corporate Bond ETF', 'HYG': 'High Yield Corporate Bond ETF',
            'GLD': 'Gold ETF', 'SLV': 'Silver ETF', 'USO': 'Oil ETF', 'DBA': 'Agriculture ETF'
        }
        logging.info(f"ETF Collector initialized. Target Dir: {self.etf_path}")

    def get_etf_data(self, symbol, start_date, end_date):
        """Tiingo APIë¥¼ í†µí•´ íŠ¹ì • ê¸°ê°„ì˜ ETF ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        start_str = start_date.strftime('%Y-%m-%d')
        end_str = end_date.strftime('%Y-%m-%d')
        url = f"{self.base_url}/tiingo/daily/{symbol}/prices"
        params = {'token': self.api_key, 'startDate': start_str, 'endDate': end_str}

        try:
            response = requests.get(url, params=params, timeout=30)
            if response.status_code == 200:
                data = response.json()
                if not data: return None  # ë°ì´í„°ê°€ ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¼ ê²½ìš° ì²˜ë¦¬

                df = pd.DataFrame(data)
                df['date'] = pd.to_datetime(df['date'])
                df.set_index('date', inplace=True)
                logging.info(f"âœ… {symbol}: Fetched {len(df)} rows.")
                return df[['adjClose']].rename(columns={'adjClose': 'Adj Close'})
            elif response.status_code == 429:
                logging.warning("Rate limit reached! Waiting for 60 seconds...")
                time.sleep(60)
            else:
                logging.error(f"{symbol}: HTTP {response.status_code}")
        except Exception as e:
            logging.error(f"{symbol}: Error: {e}")
        return None

    def collect_and_save_etf(self, symbol):
        filename = self.etf_path / f"{symbol}.csv"
        end_date = datetime.now()
        start_date = end_date - timedelta(days=self.years_back * 365)

        existing_data = None
        if filename.exists():
            try:
                existing_data = pd.read_csv(filename, index_col=0, parse_dates=True)
                latest_date = existing_data.index.max()
                if latest_date < end_date - timedelta(days=1):
                    start_date = latest_date + timedelta(days=1)
                else:
                    logging.info(f"â­ï¸ {symbol}: Already up-to-date.")
                    return True
            except Exception as e:
                logging.warning(f"File read error {symbol}: {e}. Fetching all.")

        new_data = self.get_etf_data(symbol, start_date, end_date)

        if new_data is not None and not new_data.empty:
            if existing_data is not None:
                combined_data = pd.concat([existing_data, new_data])
                combined_data = combined_data[~combined_data.index.duplicated(keep='first')].sort_index()
            else:
                combined_data = new_data

            combined_data.to_csv(filename)
            logging.info(f"ğŸ’¾ {symbol}: Saved to {filename}")
            return True
        return False

    def run_collection(self):
        logging.info("=== Starting ETF Collection ===")
        for i, symbol in enumerate(self.etfs.keys()):
            self.collect_and_save_etf(symbol)
            if i < len(self.etfs) - 1:
                time.sleep(1)  # Tiingo ë¬´ë£Œ í‹°ì–´ ì œí•œ ê³ ë ¤ (ì•½ê°„ ë¹ ë¥´ê²Œ ì¡°ì •)
        logging.info("=== Finished ===")


if __name__ == "__main__":
    ETFSmartCollector(years_back=5).run_collection()