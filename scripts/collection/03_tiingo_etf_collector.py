import requests
import time
import logging
import pandas as pd
import sys
from datetime import datetime, timedelta
from pathlib import Path
from sqlalchemy import create_engine, text

# --- [ì„¤ì • íŒŒì¼ ì—°ë™] ---
FILE = Path(__file__).resolve()
ROOT = FILE.parents[2]
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))

from config.settings import API_KEYS, LOG_DIR

# --- [DB ì ‘ì† ì •ë³´] ---
# ì‹¤ì „ì—ì„œëŠ” settings.pyì— ë„£ì§€ë§Œ, ì¼ë‹¨ ì—°ìŠµì´ë‹ˆê¹Œ ì—¬ê¸°ì— ë‘¡ë‹ˆë‹¤.
DB_URI = "postgresql+psycopg2://xodh3@localhost:5432/economy_db"

# --- [ë¡œê¹… ì„¤ì •] ---
log_file = LOG_DIR / 'etf_db_collector.log'
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(log_file),
        logging.StreamHandler()
    ]
)


class SmartETFCollector:
    def __init__(self, years_back=1):
        self.api_key = API_KEYS['TIINGO']
        self.base_url = 'https://api.tiingo.com'
        self.years_back = years_back
        self.years_back = years_back
        self.engine = create_engine(DB_URI)
        self.etfs = ['SPY', 'QQQ', 'GLD']
        logging.info("ğŸ§  Smart ETF Collector initialized.")

    def get_last_date_from_db(self, ticker):
        """DBì— ì ‘ì†í•´ì„œ í•´ë‹¹ ì¢…ëª©ì˜ 'ê°€ì¥ ë§ˆì§€ë§‰ ë‚ ì§œ'ë¥¼ ì•Œì•„ì˜µë‹ˆë‹¤."""
        try:
            with self.engine.connect() as conn:
            # ì¿¼ë¦¬: tickerê°€ ì¼ì¹˜í•˜ëŠ” ë°ì´í„° ì¤‘ ê°€ì¥ í°(MAX) ë‚ ì§œë¥¼ ê°€ì ¸ì™€ë¼
                query = text("SELECT MAX(trade_date) FROM practice_spy WHERE ticker = :ticker")
                result = conn.execute(query, {'ticker': ticker}).fetchone()

                if result and result[0]:
                    return result[0]
        except Exception as e:
            logging.warning(f"âš ï¸ {ticker} ë‚ ì§œ ì¡°íšŒ ì‹¤íŒ¨ (ì²« ìˆ˜ì§‘ìœ¼ë¡œ ê°„ì£¼): {e}")
        return None

    def get_etf_data(self, symbol, start_date, end_date):
        start_str = start_date.strftime('%Y-%m-%d')
        end_str = end_date.strftime('%Y-%m-%d')

        logging.info(f"REQUEST: {symbol} ({start_str} ~ {end_str})")

        url = f"{self.base_url}/tiingo/daily/{symbol}/prices"
        params = {'token': self.api_key, 'startDate': start_str, 'endDate': end_str}

        try:
            response = requests.get(url, params=params, timeout=30)
            if response.status_code == 200:
                data = response.json()
                if not data: return None

                df = pd.DataFrame(data)
                df['date'] = pd.to_datetime(df['date'])

                # DB í…Œì´ë¸” ì»¬ëŸ¼ëª…ì— ë§ê²Œ ë°ì´í„° ì •ë¦¬
                # practice_spy êµ¬ì¡°: ticker, trade_date, close_price
                df = df[['date', 'adjClose']].copy()
                df.columns = ['trade_date', 'close_price']  # ì´ë¦„ ë³€ê²½
                df['ticker'] = symbol  # ticker ì»¬ëŸ¼ ì¶”ê°€
                251#1*
                # ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸° (ë³´ê¸° ì¢‹ê²Œ)
                df = df[['ticker', 'trade_date', 'close_price']]

                logging.info(f"âœ… {symbol}: Fetched {len(df)} rows.")
                return df
            else:
                logging.error(f"{symbol}: HTTP {response.status_code}")
        except Exception as e:
            logging.error(f"{symbol}: Error: {e}")
        return None

    def save_to_db(self, df):
        if df is None or df.empty:
            return

        try:
            # ğŸš€ ì—¬ê¸°ê°€ í•µì‹¬! to_sqlë¡œ DBì— ë°”ë¡œ ì˜ê¸°
            # if_exists='append': ë°ì´í„°ê°€ ìˆìœ¼ë©´ ê·¸ ë’¤ì— ì´ì–´ ë¶™ì—¬ë¼
            # index=False: íŒë‹¤ìŠ¤ ìˆ«ì ì¸ë±ìŠ¤(0,1,2...)ëŠ” ë„£ì§€ ë§ˆë¼
            df.to_sql('practice_spy', self.engine, if_exists='append', index=False)
            logging.info(f"ğŸ’¾ Saved {len(df)} rows to DB (practice_spy)")
        except Exception as e:
            logging.error(f"âŒ DB Save Failed: {e}")

    def run(self):
        today = datetime.now()

        for symbol in self.etfs:
            logging.info(f"--- Checking {symbol} ---")

            # 1. DBì—ì„œ ë§ˆì§€ë§‰ ë‚ ì§œ í™•ì¸ (ì´ì–´ë‹¬ë¦¬ê¸°)
            last_db_date = self.get_last_date_from_db(symbol)

            if last_db_date:
                # ë§ˆì§€ë§‰ ë‚ ì§œê°€ ìˆìœ¼ë©´, ê·¸ 'ë‹¤ìŒ ë‚ 'ë¶€í„° ìˆ˜ì§‘ ì‹œì‘
                # last_db_dateëŠ” date íƒ€ì…ì´ë¯€ë¡œ datetimeìœ¼ë¡œ ë³€í™˜ í•„ìš”í•  ìˆ˜ ìˆìŒ
                if isinstance(last_db_date, str):
                    last_db_date = datetime.strptime(last_db_date, '%Y-%m-%d').date()

                start_date = last_db_date + timedelta(days=1)
                # start_dateë¥¼ datetime ê°ì²´ë¡œ ë³€í™˜ (API í•¨ìˆ˜ í˜¸í™˜ì„± ìœ„í•¨)
                start_date = datetime(start_date.year, start_date.month, start_date.day)

                logging.info(f"ğŸ”„ ì´ì–´ë‹¬ë¦¬ê¸°: DB ë§ˆì§€ë§‰ ë‚ ì§œëŠ” {last_db_date}. {start_date.date()}ë¶€í„° ìˆ˜ì§‘í•©ë‹ˆë‹¤.")
            else:
                # DBì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ì„¤ì •ëœ ê¸°ê°„ë§Œí¼ ìˆ˜ì§‘
                start_date = today - timedelta(days=self.years_back * 365)
                logging.info(f"ğŸ†• ì‹ ê·œ ìˆ˜ì§‘: {start_date.date()}ë¶€í„° ì‹œì‘í•©ë‹ˆë‹¤.")
                # 2. ì´ë¯¸ ìµœì‹ ì´ë©´ ê±´ë„ˆë›°ê¸°
            if start_date < today:
                logging.info(f"âœ… {symbol}ì€ ì´ë¯¸ ìµœì‹  ë°ì´í„°ì…ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

                # 3. ë°ì´í„° ìˆ˜ì§‘ ë° ì €ì¥
            df = self.get_etf_date(symbol, start_date, today)
            if df is not None and not df.empty:
                self.save_to_db(df)
            else:
                logging.info(f"ğŸ¤·â€â™‚ï¸ {symbol}: ê°€ì ¸ì˜¬ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

            time.sleep(1)

if __name__ == "__main__":
    SmartETFCollector(years_back=1).run()